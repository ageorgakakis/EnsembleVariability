{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-reflection",
   "metadata": {},
   "source": [
    "Example of the Empirical Variability Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import ensvar as var\n",
    "import astropy.io.fits as fits\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-consumption",
   "metadata": {},
   "source": [
    "The model depends on an input mock AGN catalogue. This can be generated e.g. by adoptinbg methods described in [Georgakakis et al. 2020](https://ui.adsabs.harvard.edu/abs/2020MNRAS.499..710G/abstract). The minimum number of columns of the input mock AGN table is redshift (assumed name 'Z'), stellar mass (assumed name 'LGM') and X-ray luminosity in the 2-10keV band (assumed name 'LGLX'). The catalogue is assumed to be an instance of numpy record arrays. The data read from fits files via the  astropy.io.fits module is a special subclass of numpy.recarray. In the example below the data can be read from a fits table or provided as numpy record array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "early-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "example of reading a mock AGN catalogue in fits format\n",
    "'''\n",
    "hdu = fits.open(\"../DATA/SIM_AIRD15_VAR_PHOT.fits\")\n",
    "data=hdu[1].data\n",
    "hdu.close()\n",
    "\n",
    "'''\n",
    "example of directly providing an numpy record array with the minimum\n",
    "number of information required by the Empirical Variability Model class, \n",
    "i.e. redshift ('Z'), Stellar mass ('LGM') and 2-10 keV X-ray \n",
    "luminosity ('LGLX')\n",
    "'''\n",
    "data = numpy.rec.array([(0.5,11.5, 43.0),\n",
    "                    (0.7, 10.5, 42.6),\n",
    "                    (0.8, 12.4, 43.9)],\n",
    "                    formats='float64,float64,float64',\n",
    "                    names='Z,LGM,LGLX')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-worship",
   "metadata": {},
   "source": [
    "Define the Empirical Variability Model class, providing as input:\n",
    "\n",
    "* the mock AGN catalogue, \n",
    "* the redshift range (minimum and maximum redshift) of the sample. The `ZMIN` and `ZMAX` parameters are used to filter the input catalogue of mock AGN to the specified redshifgt interval. \n",
    "* the PSD model, one of `Model1`, `Model2`, `Model3`, `Model4`. These four models correspond those proposed in [Paolillo et al. 2017] https://ui.adsabs.harvard.edu/abs/2017MNRAS.471.4398P/abstract).\n",
    "* the Black hole-mass vs stellar mass scaling realtion. These are define as functions in the ensvar.py module and include the (i) [Shankar et al. (2017)](https://ui.adsabs.harvard.edu/abs/2017ApJ...840...34S/abstract) \"unbiased\" relation (`GETMBHMSTAR_SHANKAR_SIGMA`) and (ii) the  [Shankar et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020NatAs...4..282S/abstract) scaling relation based on the dynamically derived black-hole masses estimated by [Savorgnan et al. (2016)](https://ui.adsabs.harvard.edu/abs/2016ApJ...817...21S/abstract),  (`GETMBHMSTAR_SAV_SIGMA`). Both relations above include statter. Other scaling relations are also available (e.g. a simple linear parametrisation of the form $\\log M_{BH} =  A + B \\cdot (\\log M_{star} - 11)$, where $A$, $B$ can be defined.\n",
    "* and the function that estimates the Eddington ratio of mock AGN given 2-10keV luminosities and black-hole masses. The bolometric correction is relevant to this calculation. In the current implementation the function   `GETLGLEDD` of the `ensvar.py` module assumes a simple bolometric correction $L_{BOL} = 25 \\cdot L_X(2-10\\rm \\,keV)$\n",
    "\n",
    "The Empical Model (`EmpMo`) class method `updateSTRUCT` will generate all the relevant quantities that are needed for the variability calculation, e.g. black-hole mass and Eddington ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dependent-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM=var.EmpMo(data=data, ZMIN=0.4, ZMAX=4.0, PSDfun=\"Model1\", MMfun=var.GETMBHMSTAR_SHANKAR_SIGMA, LEDDfun=var.GETLGLEDD)\n",
    "EM.updateSTRUCT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-stone",
   "metadata": {},
   "source": [
    "the attribute `DSTRUCT` (python dictionary) holds all the important quantities (numpy arrays) relevant to the empirical variability model:\n",
    "\n",
    "* `DSTRUCT[\"Z\"]`: mock AGN redshift\n",
    "* `DSTRUCT[\"WEIGHT\"]`: mock AGN weight. By default one but can be modified to emulate an observational selection function. \n",
    "* `DSTRUCT[\"LGM\"]`: mock AGN stellar mass (log10)\n",
    "* `DSTRUCT[\"LGLX\"]`: mock AGN X-ray luminosity (log10)\n",
    "* `DSTRUCT[\"LGMBH\"]`: mock AGN black hole mass (log10)\n",
    "* `DSTRUCT[\"LGLEDD\"]`: mock AGN Eddington ratio (log10)\n",
    "* `DSTRUCT[\"PSDNORM\"]`: normalisation of the PSD model (in log10)\n",
    "* `DSTRUCT[\"NUB\"]`: break frequencty of the PSD model (log10)\n",
    "* `DSTRUCT[\"SIGMA2M\"]`: model excess variance \n",
    "* `DSTRUCT[\"SIGMA2O\"]`: observed excess variance, after applying to SIGMA2M the bias factor  $C \\cdot 0.48^{\\beta-1}$ [(Allevato et al. 2013)](https://ui.adsabs.harvard.edu/abs/2013ApJ...771....9A/abstract) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sublime-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z\n",
      "WEIGHT\n",
      "LGM\n",
      "LGLX\n",
      "LGMBH\n",
      "LGLEDD\n",
      "NUB\n",
      "PSDNORM\n",
      "SIGMA2O\n",
      "SIGMA2M\n",
      "[ 7.91190804  6.25033084 10.25955448]\n"
     ]
    }
   ],
   "source": [
    "for key in EM.DSTRUCT.keys():\n",
    "    print(key)\n",
    "\n",
    "print(EM.DSTRUCT['LGMBH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-prevention",
   "metadata": {},
   "source": [
    "The determimation of the excess variance requires a minimum and maximum timescale over which the variability is observed. These are defined in days at the observer frame. The method sigma2 of the Emprical Model Class estimates the excess variance. The `EmpMo` class also includes the attribiutes `biasC` and `biasBETA`, which define the  bias factor $C \\cdot 0.48^{\\beta-1}$  [Allevato et al. 2013](https://ui.adsabs.harvard.edu/abs/2013ApJ...771....9A/abstract). This has to do with observational biases in measurements of the excess variance e.g. because of the cadence of the observations. The default values are $C=1.3$ and $\\beta=1.1$ but can be redefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "laughing-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12818806 0.16395845 0.03892825]\n",
      "[0.17544864 0.22440692 0.05328038]\n"
     ]
    }
   ],
   "source": [
    "DMINOBS=0.25\n",
    "DMAXOBS=6205\n",
    "EM.sigma2(DMINOBS, DMAXOBS)\n",
    "print(EM.DSTRUCT['SIGMA2O'])\n",
    "\n",
    "EM.biasC = 1.1\n",
    "EM.biasBETA = 1.3\n",
    "EM.sigma2(DMINOBS, DMAXOBS)\n",
    "print(EM.DSTRUCT['SIGMA2O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
